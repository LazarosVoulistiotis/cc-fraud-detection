---

# Î—Î¼Î­ÏÎ± 1 â€” Jupyter & NumPy Fundamentals (2â€“3 ÏÏÎµÏ‚)

## Î£Ï„ÏŒÏ‡Î¿Î¹
- ÎÎ± Î´Î¿Ï…Î»ÎµÏÏ‰ Î¬Î½ÎµÏ„Î± ÏƒÎµ Jupyter.
- ÎÎ± Ï€ÎµÏÎ¬ÏƒÏ‰ Ï„Î± Î²Î±ÏƒÎ¹ÎºÎ¬ Ï„Ï‰Î½ NumPy arrays: Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±, indexing, broadcasting, axis ops, reshapes.
- ÎÎ± ÎºÏÎ±Ï„Î¬Ï‰ ÎºÎ±Î¸Î±ÏÎ­Ï‚, Ï‡ÏÎ®ÏƒÎ¹Î¼ÎµÏ‚ ÏƒÎ·Î¼ÎµÎ¹ÏÏƒÎµÎ¹Ï‚.

---

## Checklist (Î³ÏÎ®Î³Î¿ÏÎ¿Ï‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚)
- [ ] Î†Î½Î¿Î¹Î¾Î± venv ÎºÎ±Î¹ Jupyter
- [ ] ÎˆÏ†Ï„Î¹Î±Î¾Î± notebook `notebooks/week2/day1_numpy.ipynb`
- [ ] ÎˆÏ„ÏÎµÎ¾Î± ÏŒÎ»Î± Ï„Î± cells Î³Î¹Î± NumPy (Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±, indexing, broadcasting, axis ops, reshape)
- [ ] ÎˆÎ»Ï…Î½Î± mini-Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚ (euclidean, z-score, dot, cov)
- [ ] ÎˆÎ³ÏÎ±ÏˆÎ± â€œGotchasâ€ + ÏƒÏÎ½Ï„Î¿Î¼Î± ÏƒÏ…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î±
- [ ] ÎˆÎºÎ±Î½Î± daily git commit & push

---

## Î’Î®Î¼Î±Ï„Î±

### 1) Jupyter basics (15â€™)
- **Î†Î½Î¿Î¹Î³Î¼Î± venv** (Windows):
  ```bash
  .\.venv\Scripts\activate.bat 
  *(ÏƒÎµ CMD)*

## Shortcuts (Ï„Î± Ï€Î¹Î¿ Ï‡ÏÎ®ÏƒÎ¹Î¼Î±):
- Î•Î½Î±Î»Î»Î±Î³Î® Ï„ÏÏ€Î¿Ï… ÎºÎµÎ»Î¹Î¿Ï: M â†’ Markdown, Y â†’ Code
- ÎÎ­Î¿ ÎºÎµÎ»Î¯: Esc + A (Ï€Î¬Î½Ï‰), Esc + B (ÎºÎ¬Ï„Ï‰)
- Î•ÎºÏ„Î­Î»ÎµÏƒÎ·: Shift + Enter
- Î”Î¹Î±Î³ÏÎ±Ï†Î® ÎºÎµÎ»Î¹Î¿Ï: DD
- ÎœÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯Î± ÎºÎµÎ»Î¹Î¿Ï: Enter ÎºÎ±Î¹ Î³ÏÎ¬ÏˆÎµ

## NumPy Ï„Î± Î±Ï€Î¿Î»ÏÏ„Ï‰Ï‚ Î²Î±ÏƒÎ¹ÎºÎ¬

1. Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® & seed
- import numpy as np
Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· NumPy ÎºÎ±Î¹ Ï„Î·Ï‚ Î´Î¯Î½ÎµÎ¹ ÏƒÏÎ½Ï„Î¿Î¼Î¿ ÏˆÎµÏ…Î´ÏÎ½Ï…Î¼Î¿ np (ÎºÎ±Î¸Î¹ÎµÏÏ‰Î¼Î­Î½Î¿ convention). ÎˆÏ„ÏƒÎ¹ Î³ÏÎ¬Ï†ÎµÎ¹Ï‚ np.array, np.mean, np.random Îº.Î»Ï€.

- np.random.seed(42)
ÎŸÏÎ¯Î¶ÎµÎ¹ seed (ÏƒÏ€ÏŒÏÎ¿) Î³Î¹Î± Ï„Î¿Î½ Ï€Î±Î»Î¹ÏŒ global Î³ÎµÎ½Î½Î®Ï„Î¿ÏÎ± Ï„Ï…Ï‡Î±Î¯Ï‰Î½ Î±ÏÎ¹Î¸Î¼ÏÎ½ Ï„Î¿Ï… NumPy. ÎœÎµ Î±Ï€Î»Î¬ Î»ÏŒÎ³Î¹Î±: Î±Ï€ÏŒ Î±Ï…Ï„Î® Ï„Î· ÏƒÏ„Î¹Î³Î¼Î® ÎºÎ±Î¹ Î¼ÎµÏ„Î¬, ÎºÎ»Î®ÏƒÎµÎ¹Ï‚ ÏŒÏ€Ï‰Ï‚ np.random.rand(), np.random.randint() Îº.Î¬. Î¸Î± Ï€Î±ÏÎ¬Î³Î¿Ï…Î½ Ï„Î·Î½ Î¯Î´Î¹Î± Î±ÎºÏÎ¹Î²ÏÏ‚ Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¯Î± â€œÏ„Ï…Ï‡Î±Î¯Ï‰Î½â€ Î±ÏÎ¹Î¸Î¼ÏÎ½ ÎºÎ¬Î¸Îµ Ï†Î¿ÏÎ¬ Ï€Î¿Ï… Ï„ÏÎ­Ï‡ÎµÎ¹Ï‚ Ï„Î¿ Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î±. Î‘Ï…Ï„ÏŒ Î»Î­Î³ÎµÏ„Î±Î¹ Î±Î½Î±Ï€Î±ÏÎ±Î³Ï‰Î³Î¹Î¼ÏŒÏ„Î·Ï„Î± (reproducibility).

Î“Î¹Î±Ï„Î¯ Î½Î± Ï„Î¿ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚:
- Î“Î¹Î± Î½Î± Î­Ï‡ÎµÎ¹Ï‚ ÏƒÏ„Î±Î¸ÎµÏÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏƒÎµ notebooks / Ï€ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î±.
- Î“Î¹Î± Î½Î± Î¼Ï€Î¿ÏÎµÎ¯ ÎºÎ¬Ï€Î¿Î¹Î¿Ï‚ Î¬Î»Î»Î¿Ï‚ Î½Î± Î±Î½Î±Ï€Î±ÏÎ¬Î³ÎµÎ¹ Ï„Î± Î¯Î´Î¹Î± Î½Î¿ÏÎ¼ÎµÏÎ± Î¼Îµ ÎµÏƒÎ­Î½Î±.

Î£Ï…Ï‡Î½Î­Ï‚ Î±Ï€Î¿ÏÎ¯ÎµÏ‚ & Ï€Î±Î³Î¯Î´ÎµÏ‚:
- Î¤Î¿ 42 ÎµÎ¯Î½Î±Î¹ Î±Ï€Î»ÏÏ‚ Î­Î½Î±Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚-Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± (Î´Î¹Î¬ÏƒÎ·Î¼Î¿ meme). ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ¯Î½Î±Î¹ Î¿Ï€Î¿Î¹Î¿ÏƒÎ´Î®Ï€Î¿Ï„Îµ Î±ÎºÎ­ÏÎ±Î¹Î¿Ï‚ ÏƒÏ„Î¿ ÎµÏÏÎ¿Ï‚ 0 Î­Ï‰Ï‚ 2Â³Â²âˆ’1.
- ÎšÎ±Î»ÏŒ ÎµÎ¯Î½Î±Î¹ Î½Î± ÎºÎ¬Î½ÎµÎ¹Ï‚ seed Î¼Î¯Î± Ï†Î¿ÏÎ¬ ÏƒÏ„Î·Î½ Î±ÏÏ‡Î®. Î‘Î½ Ï„Î¿ Î²Î¬Î¶ÎµÎ¹Ï‚ Î¼Î­ÏƒÎ± ÏƒÎµ loop, Î¸Î± â€œÎ¾Î±Î½Î±ÏÏ‡Î¯Î¶ÎµÎ¹â€ Î· Î¯Î´Î¹Î± Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¯Î± ÎºÎ¬Î¸Îµ ÎµÏ€Î±Î½Î¬Î»Î·ÏˆÎ·.
- Î•Ï€Î·ÏÎµÎ¬Î¶ÎµÎ¹ Î¼ÏŒÎ½Î¿ Ï„Î¿ NumPy (np.random.*). Î”ÎµÎ½ ÎµÏ€Î·ÏÎµÎ¬Î¶ÎµÎ¹ Ï„Î¿ random Ï„Î·Ï‚ Python Î® Ï„Ï…Ï‡ÏŒÎ½ RNG Î¬Î»Î»Ï‰Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î·ÎºÏÎ½ (Ï€.Ï‡. PyTorch, TensorFlow) â€” Î±Ï…Ï„Î¬ Î¸Î­Î»Î¿Ï…Î½ Î´Î¹ÎºÏŒ Ï„Î¿Ï…Ï‚ seed.

2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± arrays
- np.array([...]) â†’ Ï‡ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î· Î»Î¯ÏƒÏ„Î± ÏƒÎµ NumPy array.
- np.arange(start, stop, step) â†’ â€œrangeâ€ Î¼Îµ Î²Î®Î¼Î±.
- np.linspace(start, stop, num) â†’ Î¹ÏƒÎ±Ï€Î­Ï‡Î¿Ï…ÏƒÎµÏ‚ Ï„Î¹Î¼Î­Ï‚.
- np.zeros(shape) â†’ Î¼Î·Î´ÎµÎ½Î¹ÎºÎ¬.
- np.ones(shape) â†’ Î¬ÏƒÏƒÎ¿Î¹.
- np.random.rand(shape) â†’ Ï„Ï…Ï‡Î±Î¯Î¿Î¹ Î´ÎµÎºÎ±Î´Î¹ÎºÎ¿Î¯ [0,1).
- np.random.randint(low, high, size) â†’ Ï„Ï…Ï‡Î±Î¯Î¿Î¹ Î±ÎºÎ­ÏÎ±Î¹Î¿Î¹ [low, high).

3. Î™Î´Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ array
- dtype â†’ Ï„ÏÏ€Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Ï€.Ï‡. float64).
- shape â†’ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Ï€Î¯Î½Î±ÎºÎ± (Ï€.Ï‡. 3x4).
- ndim â†’ Ï€ÏŒÏƒÎµÏ‚ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î­Ï‡ÎµÎ¹ (ÎµÎ´Ï 2D).
- size â†’ Ï€ÏŒÏƒÎ± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Î­Ï‡ÎµÎ¹ ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬.
- itemsize â†’ Ï€ÏŒÏƒÎ± bytes Ï€Î¹Î¬Î½ÎµÎ¹ ÎºÎ¬Î¸Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ ÏƒÏ„Î· Î¼Î½Î®Î¼Î·.

4. Indexing & Slicing
- arr[start:end:step] â†’ slicing ÏƒÎµ 1D.
- M[row, col] â†’ indexing ÏƒÎµ 2D.
- : â†’ â€œÏ€Î¬ÏÎµ ÏŒÎ»Î±â€.
- -1 â†’ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± Î¸Î­ÏƒÎ·.
- ÎœÏ€Î¿ÏÎµÎ¯Ï‚ Î½Î± ÎºÏŒÏˆÎµÎ¹Ï‚ Ï…Ï€Î¿Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ slicing ÏŒÏ€Ï‰Ï‚ M[0:2, 1:3]

5. Boolean masking & filtering
- Î¤Î¿ mask ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Î±Ï€ÏŒ True/False.
- ÎŒÏ„Î±Î½ Ï„Î¿ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï‚ ÏƒÎ±Î½ Î´ÎµÎ¯ÎºÏ„Î· (vals[mask]), Ï€Î±Î¯ÏÎ½ÎµÎ¹Ï‚ Î¼ÏŒÎ½Î¿ Ï„Î± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Ï€Î¿Ï… Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¹Ï‡Î¿ÏÎ½ ÏƒÎµ True.
- Î‘Ï…Ï„ÏŒ Î»Î­Î³ÎµÏ„Î±Î¹ boolean indexing (Î® filtering).
ğŸ‘‰ Î Î¿Î»Ï ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒ: Ï„Î¿ filtered ÎµÎ´Ï ÎµÎ¯Î½Î±Î¹ ÎºÎ±Î¹Î½Î¿ÏÏÎ³Î¹Î¿ array (copy), ÏŒÏ‡Î¹ view. Î‘Î½ Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ Ï„Î¿ filtered, Î´ÎµÎ½ ÎµÏ€Î·ÏÎµÎ¬Î¶ÎµÎ¹ Ï„Î¿ vals.

6. Broadcasting (Ï€ÏÏŒÏƒÎ¸ÎµÏƒÎ· vector ÏƒÎµ matrix, scaling)
- Broadcasting = ÏŒÏ„Î±Î½ Î¿Î¹ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ 2 Ï€Î¹Î½Î¬ÎºÏ‰Î½ Î´ÎµÎ½ Ï„Î±Î¹ÏÎ¹Î¬Î¶Î¿Ï…Î½ Î±ÎºÏÎ¹Î²ÏÏ‚, Ï„Î¿ NumPy Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯ Î½Î± Ï„Î¹Ï‚ Â«Ï„ÎµÎ½Ï„ÏÏƒÎµÎ¹Â» Î³Î¹Î± Î½Î± Î³Î¯Î½Î¿Ï…Î½ ÏƒÏ…Î¼Î²Î±Ï„Î­Ï‚.
- A + v â†’ broadcasting Ï„Î¿Ï… v ÎºÎ±Ï„Î¬ Î¼Î®ÎºÎ¿Ï‚ Ï„Ï‰Î½ Î³ÏÎ±Î¼Î¼ÏÎ½.
- 2 * A â†’ scalar Ï€Î¿Î»Î»Î±Ï€Î»Î±ÏƒÎ¹Î±ÏƒÎ¼ÏŒÏ‚ (Ï„Î¿ 2 Î³Î¯Î½ÎµÏ„Î±Î¹ ÏƒÎ±Î½ Î½Î± Î®Ï„Î±Î½ array Î¯Î´Î¹Î¿Ï… ÏƒÏ‡Î®Î¼Î±Ï„Î¿Ï‚ Î¼Îµ Ï„Î¿ A).

7. Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Ï„Î¬ axis
- axis=0 â†’ Ï€ÏÎ¬Î¾Î· Î±Î½Î¬ ÏƒÏ„Î®Î»Î·.
- axis=1 â†’ Ï€ÏÎ¬Î¾Î· Î±Î½Î¬ Î³ÏÎ±Î¼Î¼Î®.
- Î§Ï‰ÏÎ¯Ï‚ axis, Î¿Î¹ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ Î´Î¿Ï…Î»ÎµÏÎ¿Ï…Î½ ÏƒÎµ ÏŒÎ»Î¿ Ï„Î¿ array.

8. Reshape / Ravel / Flatten / 
- reshape â†’ Î±Î»Î»Î¬Î¶ÎµÎ¹ ÏƒÏ‡Î®Î¼Î± (Î´ÎµÎ½ Î±Î»Î»Î¬Î¶ÎµÎ¹ Î´ÎµÎ´Î¿Î¼Î­Î½Î±).
- ravel() â†’ flatten view (ÏŒÏ€Î¿Ï… Î³Î¯Î½ÎµÏ„Î±Î¹).
- flatten() â†’ flatten copy (Ï€Î¬Î½Ï„Î±).
- concatenate â†’ Î³ÎµÎ½Î¹ÎºÎ® ÏƒÏ…Î½Î­Î½Ï‰ÏƒÎ· arrays.
- vstack = ÎºÎ¬Î¸ÎµÏ„Î· ÏƒÏ„Î¿Î¯Î²Î±Î¾Î·, hstack = Î¿ÏÎ¹Î¶ÏŒÎ½Ï„Î¹Î± ÏƒÏ„Î¿Î¯Î²Î±Î¾Î·.

9. Vectorization vs Loops (%%timeit)
Î— vectorization (Ï€ÏÎ¬Î¾ÎµÎ¹Ï‚ Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ ÏƒÎµ NumPy arrays) ÎµÎ¯Î½Î±Î¹ Î¸ÎµÎ¼Î­Î»Î¹Î¿ ÏƒÏ„Î· Python Î³Î¹Î± Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¿ÏÏ‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿ÏÏ‚. Î‘Ï€Î¿Ï†ÎµÏÎ³ÎµÎ¹Ï‚ Ï„Î± Python loops ÎºÎ±Î¹ ÎµÎºÎ¼ÎµÏ„Î±Î»Î»ÎµÏÎµÏƒÎ±Î¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ C backend.

---

## 3.1 Î•Ï…ÎºÎ»ÎµÎ¯Î´ÎµÎ¹Î± Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ· (Ï‡Ï‰ÏÎ¯Ï‚ loop)
- np.linalg.norm(u-v) = Î•Ï…ÎºÎ»ÎµÎ¯Î´ÎµÎ¹Î± Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï u ÎºÎ±Î¹ v.
- Î Î¿Î»Ï Ï‡ÏÎ®ÏƒÎ¹Î¼Î¿ ÏƒÎµ ML (Ï€.Ï‡. KNN (K-Nearest Neighbors), clustering).
- ÎœÏ€Î¿ÏÎµÎ¯Ï‚ ÎºÎ±Î¹ Î¼Îµ Î¬Î»Î»Î± norms: np.linalg.norm(u-v, ord=1) â†’ Manhattan distance (calculate the distance between two points in a grid-like space, ord=np.inf â†’ Chebyshev Îº.Î¬.

## 3.2 Standardization (zâ€‘score) Î±Î½Î¬ ÏƒÏ„Î®Î»Î· ÏƒÎµ 2D array
- ÎˆÎºÎ±Î½ÎµÏ‚ Z-score standardization ÏƒÎµ ÎºÎ¬Î¸Îµ ÏƒÏ„Î®Î»Î·. ( A data transformation technique where each data point is converted into a z-score, which indicates how many standard deviations it is from the mean of the dataset. This process results in a standardized dataset with a mean of 0 and a standard deviation of 1. The main purpose of z-score standardization is to put data from different scales or units onto a common scale, making it easier to compare, analyze, and process. )
- Î¤ÏÏÎ± ÏŒÎ»ÎµÏ‚ Î¿Î¹ ÏƒÏ„Î®Î»ÎµÏ‚ Î­Ï‡Î¿Ï…Î½ Î¯Î´Î¹Î¿ scale â†’ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿ Î²Î®Î¼Î± Ï€ÏÎ¹Î½ Î±Ï€ÏŒ Ï€Î¿Î»Î»Î¬ ML Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…Ï‚ (Ï€.Ï‡. PCA, SVM, gradient descent).

## 3.3 Dot product, elementwise product, covariance matrix
- np.dot â†’ scalar (Î® matrix multiplication ÏƒÎµ 2D).
- * â†’ elementwise.
- np.cov â†’ covariance matrix (features Ã— features), Ï‡ÏÎ®ÏƒÎ¹Î¼Î¿ ÏƒÎµ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ®, PCA (Principal component analysis), ML

# âœ… Mini-Î‘ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚ NumPy â†’ ML Pipelines Checklist

| Mini-Î†ÏƒÎºÎ·ÏƒÎ· | Î¤ÎµÏ‡Î½Î¹ÎºÎ® Ï€Î¿Ï… Î­Î¼Î±Î¸Î± | ML Î‘Î½Ï„Î¯ÎºÏÎ¹ÏƒÎ¼Î± | Î£Î·Î¼ÎµÎ¹ÏÏƒÎµÎ¹Ï‚ / Î”Î¹ÎºÎ¬ Î¼Î¿Ï… Î Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î± |
|-------------|-------------------|---------------|------------------------------------|
| `np.random.seed` | Î‘Î½Î±Ï€Î±ÏÎ±Î³Ï‰Î³Î¹Î¼ÏŒÏ„Î·Ï„Î± | Î£Ï„Î±Î¸ÎµÏÎ¬ splits, Î¯Î´Î¹Î± init weights | [ ] |
| `np.arange`, `np.linspace`, `np.zeros`, `np.ones`, `np.random` | Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± arrays | Synthetic data, Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î²Î±ÏÏÎ½ | [ ] |
| Indexing / Slicing | Î•Ï€Î¹Î»Î¿Î³Î® Ï…Ï€Î¿ÏƒÏ…Î½ÏŒÎ»Ï‰Î½ | Train/test split, mini-batches, ÎµÏ€Î¹Î»Î¿Î³Î® features | [ ] |
| Boolean Masking | Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î± Î¼Îµ ÏƒÏ…Î½Î¸Î®ÎºÎµÏ‚ | Î•Ï€Î¹Î»Î¿Î³Î® samples Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ threshold | [ ] |
| Broadcasting (`A+v`, `2*A`) | Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÎµÏ…Î¸Ï…Î³ÏÎ¬Î¼Î¼Î¹ÏƒÎ· | Bias add, feature scaling | [ ] |
| Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ (`mean`, `std`, `sum` Î¼Îµ axis) | Aggregation Î±Î½Î¬ ÏƒÏ„Î®Î»Î·/Î³ÏÎ±Î¼Î¼Î® | Normalization, losses, batch statistics | [ ] |
| Reshape / Ravel / Flatten | Î‘Î»Î»Î±Î³Î® ÏƒÏ‡Î®Î¼Î±Ï„Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ | Î•Î¹ÎºÏŒÎ½ÎµÏ‚â†’vectors, flatten CNN layers | [ ] |
| Concatenate / Stack | Î£Ï…Î½Î­Î½Ï‰ÏƒÎ· arrays | Merge datasets, data augmentation | [ ] |
| Loop vs Vectorization | Î‘Ï€ÏŒÎ´Î¿ÏƒÎ· | Î“ÏÎ®Î³Î¿ÏÎ¿ preprocessing Î¼ÎµÎ³Î¬Î»Ï‰Î½ datasets | [ ] |
| Euclidean Distance (`np.linalg.norm`) | Î‘Ï€ÏŒÏƒÏ„Î±ÏƒÎ· Î´Î¹Î±Î½Ï…ÏƒÎ¼Î¬Ï„Ï‰Î½ | KNN, K-Means, similarity | [ ] |
| Standardization (z-score) | (x-Î¼)/Ïƒ | Scaling Ï€ÏÎ¹Î½ training (SVM, NN, Logistic) | [ ] |
| Dot Product vs Elementwise | Î”Î¹Î±Ï†Î¿ÏÎ¬ dot vs Hadamard | Cosine similarity, attention mechanisms | [ ] |
| Covariance Matrix (`np.cov`) | Î£Ï…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ· features | PCA, correlation analysis | [ ] |

## Î£Ï…Î½Î®Î¸Î· Gotchas
- Views vs Copies: Î Î¿Î»Î»Î¬ slicing/ravel() Î´Î¯Î½Î¿Ï…Î½ view (Î¿Î¹ Î±Î»Î»Î±Î³Î­Ï‚ Î±Î½Ï„Î¹ÎºÎ±Ï„Î¿Ï€Ï„ÏÎ¯Î¶Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿ Î±ÏÏ‡Î¹ÎºÏŒ). Î‘Î½ Î¸Î­Î»ÎµÎ¹Ï‚ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î¿ array, ÎºÎ¬Î½Îµ copy() Î® flatten().
- Dtype upcasting: Î ÏÎ¬Î¾ÎµÎ¹Ï‚ Î¼ÎµÏ„Î±Î¾Ï int/float Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î±Î»Î»Î¬Î¾Î¿Ï…Î½ Ï„ÏÏ€Î¿. ÎˆÎ»ÎµÎ³Î¾Îµ/ÏŒÏÎ¹ÏƒÎµ dtype Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹.
- Broadcasting rules: Î¤Î± ÏƒÏ‡Î®Î¼Î±Ï„Î± â€œÎµÏ…Î¸Ï…Î³ÏÎ±Î¼Î¼Î¯Î¶Î¿Î½Ï„Î±Î¹â€ Î±Ï€ÏŒ Ï„Î± Î´ÎµÎ¾Î¹Î¬. Î‘Î½ Î¼Î¯Î± Î´Î¹Î¬ÏƒÏ„Î±ÏƒÎ· ÎµÎ¯Î½Î±Î¹ 1 Î® Î¯Î´Î¹Î±, Î³Î¯Î½ÎµÏ„Î±Î¹ broadcast. Î‘Î»Î»Î¹ÏÏ‚ ÏƒÏ†Î¬Î»Î¼Î±.
- Axis Ï€Î±ÏÎµÎ¾Î®Î³Î·ÏƒÎ·: axis=0 ÎµÎ¯Î½Î±Î¹ ÎºÎ¬Î¸ÎµÏ„ÎµÏ‚ Ï€ÏÎ¬Î¾ÎµÎ¹Ï‚ Î±Î½Î¬ ÏƒÏ„Î®Î»Î·, axis=1 Î¿ÏÎ¹Î¶ÏŒÎ½Ï„Î¹ÎµÏ‚ Î±Î½Î¬ Î³ÏÎ±Î¼Î¼Î®.
- np.cov default: Î‘Ï€ÏŒ Ï€ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î® Î¸ÎµÏ‰ÏÎµÎ¯ ÎºÎ¬Î¸Îµ Î³ÏÎ±Î¼Î¼Î® Ï‰Ï‚ variable (rowvar=True). Î“Î¹Î± ÎºÎ»Î±ÏƒÎ¹ÎºÏŒ (samples, features) Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ rowvar=False.